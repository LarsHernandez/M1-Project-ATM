---
title: "Project M1"
author: "Andreas, Simon, Jess, Lars"
date: "14/9/2019"
output:
  html_document:
    code_folding: hide
    theme: flatly
    toc: yes
    toc_float:
      collapsed: no
---

# SparNord ATM transactions
Predictive moddeling of EURO vs. Non-EURO transactions


```{r eval=FALSE, include=FALSE}
#pacman::p_load(tidyverse, ggforce, caret, VIM, gridExtra, 
#               ggmap, osmdata, sf, geosphere, yardstick, 
#               knitr, ggthemes, ggridges, kableExtra)
```


```{r PACKAGES, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggforce)
library(caret)
library(yardstick)
library(knitr)
library(ggthemes)
library(ggridges)
library(kableExtra)
library(gridExtra)
library(VIM)
library(ggridges)
library(ggmap)
library(osmdata)
library(sf)
library(GGally)
library(FactoMineR)
library(geosphere)
library(sf)

base <- "#1f83b4"

load(file="generated_data/sATM.Rdata")
load(file="generated_data/bATM.Rdata")

set.seed(20092019)
```


## Data

```{r MAP, fig.height=6, fig.width=11, message=FALSE, warning=FALSE}
coord <- as.matrix(data.frame(min = c(8, 55), 
                              max = c(13, 58), 
                              row.names = c("x","y")))

s <- bATM %>% filter(atm_lat > coord[2,1] & atm_lat < coord[2,2] & 
                     atm_lon < coord[1,2] & atm_lon > coord[1,1]) %>% 
  group_by(atm_id) %>% 
  summarize(n   = n(),
            lat = first(atm_lat),
            lon = first(atm_lon),
            man = first(atm_manufacturer))


# First map ---------------------------------------------------------------
map9  <- get_stamenmap(coord, zoom = 9,  maptype = "toner-lite", force = TRUE)

p1 <- ggmap(map9) +
  geom_point(data = s, aes(lon,lat, size=n/1000), alpha = 0.8) + 
  scale_size(range = c(0.5, 8)) +
  labs(title="SparNord ATM transactions in 2017", 
       subtitle = "size equals number of transactions", size="N in 1000s")

p2 <- ggmap(map9) +
  stat_density_2d(data = s, aes(lon,lat, fill = ..level..), geom = "polygon", alpha = .4) +
  #scale_fill_viridis_c(option = "magma") +
  scale_fill_gradient2(midpoint=0.5,low = "black", mid = base, high = "white") +
  labs(title="SparNord ATM transactions in 2017", 
       subtitle = "Density of ATM placement")

grid.arrange(p1,p2, nrow=1)
```



```{r fig.height=3, fig.width=10}
s1 <- bATM %>% group_by(month) %>% summarize(n=n()/1000) %>% 
  ggplot(aes(month,n))   + geom_col(fill=base, width=0.8)     + 
  labs(title = "By month") + 
  theme(axis.text.x = element_text(angle = 90, vjust=-0.1))

s2 <- bATM %>% group_by(day) %>% summarize(n=n()/1000) %>% 
  ggplot(aes(day,n)) + geom_col(fill=base, color=base)         + 
  labs(title = "By day")

s3 <- bATM %>% group_by(weekday) %>% summarize(n=n()/1000) %>% 
  ggplot(aes(weekday,n)) + geom_col(fill=base, width=0.8) + 
  labs(title = "By weekday") + 
  theme(axis.text.x = element_text(angle = 90, vjust=-0.1))

s4 <- bATM %>% group_by(hour) %>% summarize(n=n()/1000) %>% 
  ggplot(aes(hour,n))    + geom_col(fill=base, color=base)       + 
  labs(title = "By hour") + 
  scale_x_continuous(breaks=c(0,3,6,9,12,15,18,21,24))

grid.arrange(s1,s3,s2,s4, nrow=1)
```


```{r fig.height=3, fig.width=10}
bATM$Euro <- as.factor(ifelse(bATM$currency=="DKK", FALSE, TRUE))
s5 <- bATM %>% filter(Euro == T) %>% group_by(month) %>% summarize(n=n()) %>% ggplot(aes(month,n)) + geom_col(fill=base)

grid.arrange(s5)

#fATM %>% 
#  group_by(atm_id) %>% 
#  summarize(n=n(), area = first(weather_city_name)) %>% 
#  ggplot(aes(reorder(atm_id,n), n, fill=as.factor(area))) + 
#  geom_col()
```








## Feature generation

```{r eval=FALSE, message=FALSE, warning=FALSE}
# Features for the data ---------------------------------------------------
#sATM <- bATM

# Holidays ----------------------------------------------------------------
# Ferie i Nordjylland (http://skoleferie-dk.dk/skoleferie-nordjylland/)

Vinter <- ifelse(( sATM$month == "February" & 11 <= sATM$day & sATM$day <= 26), TRUE, FALSE)
Paaske <- ifelse(( sATM$month == "April"    & 8  <= sATM$day & sATM$day <= 17), TRUE, FALSE)
Efter  <- ifelse(( sATM$month == "October"  & 14 <= sATM$day & sATM$day <= 22), TRUE, FALSE)
Jul    <- ifelse(((sATM$month == "December" & 20 <= sATM$day) | (sATM$month=="January" & sATM$day<=4)), TRUE, FALSE)
Sommer <- ifelse(((sATM$month == "June"     & 23 <= sATM$day) | (sATM$month=="July"    & sATM$day>=1)| (sATM$month=="August" & sATM$day<=13)), TRUE, FALSE)
sATM$Holliday <- Jul | Vinter | Paaske | Sommer | Efter

# Distance to other ATMs --------------------------------------------------

mat <- as.matrix(data.frame(lon = sATM$atm_lon, 
                            lat = sATM$atm_lat))

Aal.luft <- c(9.842829962, 57.088999644)
Bil.luft <- c(9.150999396, 55.73749705)
Cph.luft <- c(12.650462,   55.620750)

#Distance is in meter and a straight line:
sATM$Aal.luft <- distHaversine(mat, Aal.luft, r = 6378137)
sATM$Bil.luft <- distHaversine(mat, Bil.luft, r = 6378137)
sATM$Cph.luft <- distHaversine(mat, Cph.luft, r = 6378137)

#Nearest airport in km:
sATM <- sATM %>% 
  mutate(Airportdist = round(pmin(sATM$Aal.luft,sATM$Bil.luft,sATM$Cph.luft)/1000,2))

#Divid clock
sATM$Time <- ifelse((sATM$hour >= 4  & sATM$hour <= 9),  "Morning", NA)
sATM$Time <- ifelse((sATM$hour >= 10 & sATM$hour <= 15), "Midday",  sATM$Time)
sATM$Time <- ifelse((sATM$hour >= 16 & sATM$hour <= 21), "Evening", sATM$Time)
sATM$Time <- ifelse((sATM$hour >= 22 | sATM$hour <= 3),  "Night",   sATM$Time)

#Divid the days
sATM$Weekend <- ifelse(sATM$weekday == "Saturday" | sATM$weekday == "Sunday", TRUE, FALSE)
#Valuta
sATM$Euro <- as.factor(ifelse(sATM$currency=="DKK", FALSE, TRUE))
#Payout
sATM$Payout <- ifelse((sATM$day <=4 | sATM$day >= 27), TRUE, FALSE)
#Customer
sATM$Customer <- str_detect(sATM$card_type, pattern = "on-us")
#Cardtype
sATM$Card <- sapply(strsplit(sATM$card_type, split = ' - on-us', fixed = TRUE), function(x) (x[1]))
sATM$Card <- as.factor(sATM$Card)

#Region
loc <- sATM %>% group_by(atm_id) %>% 
  summarize(x=first(atm_lon), y=first(atm_lat))

reg <- NA
for (i in 1:nrow(loc)) {
  aa <- read_csv(paste0("http://dawa.aws.dk/kommuner/reverse?x=",loc$x[i] ,"&y=",loc$y[i]))
  reg[i] <- as.character(aa[10,])
}
loc$Region <- reg

sATM <- merge(sATM,loc[,c(1,4)],by ="atm_id")
sATM$Region <- sapply(strsplit(sATM$Region, split='": "', fixed=TRUE), function(x) (x[2]))
sATM$Region <- as.factor(sATM$Region)

sATM$Id       <- as.factor(sATM$atm_id)
sATM$Time     <- as.factor(sATM$Time)
sATM$Holliday <- as.factor(sATM$Holliday)
sATM$Customer <- as.factor(sATM$Customer)
sATM$Weekend  <- as.factor(sATM$Weekend)
sATM$Payout   <- as.factor(sATM$Payout)

#Final dataset
fsATM <- sATM %>% select(Id, Holliday, Airportdist, Time, 
                         Euro, Customer, Card, Weekend, Payout, Region)

save(fsATM, file = "generated_data/fsATM.Rdata")
```



The first step is to prepare the raw data for our analysis. The raw dataset doesn't need to be cleaned, because it's pretty complete for our purpose. Based on the problem statement we want the algorithm to predict from following parameters:

- Holliday
  This parameter contains information about the specific day, is it a "normal" day or a day in the vacation, the parameter are therefore logical.     It's contructed on day and month from the raw dataset. Information about vacation are taken from: http://skoleferie-dk.dk/skoleferie-nordjylland/.   We argue that the purpose for Euro are bigger in the vacation then else, which should provide usefull information to the algorithm.
  
- Airport distance
  This parameter contains information about the distance to the closest airport, the parameter are therefore numerical. It's contructed on the        longitude and laditude on each ATM from the raw dataset and the included airports. The included airports are Aalborg, Billund and Copenhagen. The   hypotese is that, when flying your destination are likely an Euro-country, which means that ATM closest to an airport would be used to get euro.
  
- Time
  This parameter contains information about the time of the day, which are grouped into 4: morning (04-09), midday (10-15), evening (16-21) and       night (22-03), the parameter are therefore a character. It's contructed on hour from the raw dataset. This parameter should help the algorithm,     beacuse it's most likely that an euro-transaction is conducted beteewn 10-15. The reason behind is that in Denmark we use DKK, which means these    transactions are more likely to happen anytime and spontaneously, where euro-transaction is believed to be prepared and with a purpose.

- Weekday
  This parameter contains information about day, which are grouped into 2: weekday and weekend, the parameter are therefore a character. It's         contructed on day from the raw dataset. This parameter should help the algorithm to be more precise combined with the other parameters. There are   no specific reason behind.
  
- Payout
  This parameter contains information about the time you get payed (salary, transfer payments etc.), which typical happen beteewn the 27th and 31th   of each month and in relation to this you would withdraw our money beteewn the 1st and 4th. The parameter are therefore logical and contructed on   day and month from the raw dataset. The probability of a DKK-transaction is therefore believed to be very high in this date period.

- Customer
  This parameter contains information about the person behind the transaction, since it's data form SparNord, we can tell if the person is a          customer or not. The parameter are therefore a logical and contructed on card_type with the text "on-us" from the raw dataset. We argue an          euro-transaction are higher among customers of the bank since there are fees on these transactions for the non-customers.
  
- Region
  This parameter contains information about the region, which are grouped into 4: Region Nordjylland, Region Midtjylland, Region Syddanmark, Region   Sj?lland and Region Hovedstaden. The parameter are therefore a character. It's contructed on the longitude and laditude from the raw dataset and    the specific longitude and laditudes belonging to each region. Since it's SparNord data most of the transactions are believed to be conducted in    Region Nordjylland, where the use of euro is modestly.
  
- ATM ID
  This parameter contains information about each specific ATM there are in the dataset which is 113. The parameter are therefore 
  categorically. It's contructed on atm_id from the raw dataset. We are not sure all of the ATMs have the option to withdraw euro, and therefore we   make this parameter to remove the doubt.
  
- Cardtype
  This parameter contains information about each cardtype used in the ATMs, which are grouped into 9 categories and the parameter are therefore a     character. It's contructed on card_type from the raw dataset. We believe some of the cardtypes are more used to withdraw euro then others.
  
This can be presented as:

$$Euro = Holliday + Airport + Time + Weekday + Payout + Customer + Region + ATM.ID + Cardtype$$


### Control of Features

```{r}
load(file = "generated_data/fsATM.Rdata")
load(file = "generated_data/fbATM.Rdata")
load(file = "generated_data/fdata.Rdata")
```




```{r}
fbATM %>% 
  group_by(Euro) %>% 
  summarize(MeanDistance = mean(Airportdist)) %>% kable
```





```{r}
tab <- table(fbATM$Holliday, fbATM$Euro)
tab %>% kable
paste0("Proportion of non-EURO transactions during vacations ", round(tab[2,1] / sum(tab[,1]),2),"%")
paste0("Proportion of EURO transactions during vacations ", round(tab[2,2] / sum(tab[,2]),2),"%")
summary(tab)

```



```{r fig.height=2, fig.width=10}
table(fbATM$Euro, fbATM$Id) %>% 
  prop.table(margin=2) %>% 
  as.data.frame %>% 
  filter(Var1==T) %>% 
  ggplot(aes(reorder(Var2, Freq), Freq)) + 
  geom_col(fill=base, color=base) + 
  labs(x="ATM id", legend="Euro", title="Percentage of EURO transactions by each ATM machine", 
       subtitle="Machine 99 has almost 50% Euro transactions, but it's an internal ATM") + 
  theme(axis.text.x=element_text(size=4))

```





## Unsupervised Models

```{r message=FALSE, warning=FALSE, paged.print=FALSE}

vars <- c("day","hour","atm_id","atm_street_number","atm_zipcode","atm_lat",
          "atm_lon","message_code","weather_lat","weather_lon","weather_city_id",
          "temp","pressure","humidity","wind_speed","wind_deg","rain_3h",
          "clouds_all","weather_id")

```

```{r fig.height=5, fig.width=10}
ggcorr(sATM[vars], label = TRUE, label_size = 2, label_round = 2, hjust = 0.90) + 
  labs(title="Correlation among variables", fill="Correlation") + coord_cartesian(expand=T)

ggcorr(sATM[vars], label = TRUE, label_size = 2, label_round = 2, hjust = 0.90) + 
  labs(title="Correlation among variables", fill="Correlation") + 
  coord_cartesian(expand=T)

#unique(sATM$message_code)
#summary(sATM$message_code)

```

```{r fig.height=3, fig.width=10}
sATM[,vars] %>% 
  aggr(col = c('white',base), 
       numbers = TRUE, 
       sortVars = TRUE, 
       labels = names(sATM[,vars]), 
       cex.axis = 0.5, 
       gap = 0.5, 
       ylab=c("Missing data","Pattern"))
```

### PCA

```{r fig.height=3, fig.width=10}
#sATM <- sATM %>% select(-weather_lat, -weather_lon)
vars2 <- c("day","hour","atm_id","atm_street_number","atm_zipcode","atm_lat",
           "atm_lon","weather_city_id","temp","pressure","humidity","wind_speed",
           "wind_deg","clouds_all", "weather_id")

pca <- sATM[,vars2] %>% 
  map_dfc(.f = scale) %>% 
  prcomp(rank=4)

summary(pca)

a <- summary(pca)
df1 <- a$importance[2,] %>% as_tibble %>% gather(variable, value) %>% mutate(type="Change", N=c(1:nrow(.)))
df2 <- a$importance[3,] %>% as_tibble %>% gather(variable, value) %>% mutate(type="Accumulated", N=c(1:nrow(.)))

rbind(df1,df2) %>% as_tibble %>% 
  ggplot(aes(N, value)) + 
  geom_line(size=1.5, color=base) + 
  geom_point(size=3, shape=21, fill="white", color=base, stroke=2) + 
  facet_wrap(~type, scale="free") + scale_x_continuous(breaks=c(0:15)) + 
  labs(title="Screeplot: Number of factors in PCA", x="Number of factors")



loadings <- pca$rotation %>% 
  abs() %>% 
  sweep(2, colSums(.), "/") %>% 
  as.data.frame %>% 
  rownames_to_column("name")

loadings[,-1] <- apply(loadings[,-1], MARGIN = 2, FUN = round, digits=2)
head
a <- loadings %>% dplyr::select(name, PC1) %>% arrange(desc(PC1)) %>% head(6)
b <- loadings %>% dplyr::select(name, PC2) %>% arrange(desc(PC2)) %>% head(6)
c <- loadings %>% dplyr::select(name, PC3) %>% arrange(desc(PC3)) %>% head(6)
d <- loadings %>% dplyr::select(name, PC4) %>% arrange(desc(PC4)) %>% head(6)

kable(cbind(a,b,c,d)) %>% kable_styling("condensed")


#pca1 <- sATM[,vars2] %>%
#  PCA(scale.unit = TRUE, graph = FALSE)
#
#pca1 %>% 
#  fviz_screeplot(addlabels = TRUE, 
#                 ncp = 10, 
#                 ggtheme = theme_gray())

```


```{r}
#pca2 %>% 
#  fviz_screeplot(addlabels = TRUE, 
#                 ncp = 10, 
#                 ggtheme = theme_gray())

```


```{r}

#sATM %>% select(-rain_3h,-weather_lon, -weather_lat, -message_code, -message_text)
  
#sATM[,vars2] %>% 
#  scale() %>%
#  fviz_nbclust(kmeans, method = "wss")  

```



### Kmeans

```{r fig.height=3, fig.width=10}
#km %>% 
#  fviz_cluster(data = sATM[,vars2],
#               ggtheme = theme_gray()) 

wss <- 0
for (i in 1:15) {
  wss[i] <- kmeans(sATM[,vars2], centers = i, nstart=20)$tot.withinss
}

scree <- tibble(wss, N=1:15)

ggplot(scree, aes(N, wss)) + 
  geom_line(size=1.5, color=base) + 
  geom_point(size=3, shape=21, fill="white", color=base, stroke=2) + 
  scale_x_continuous(breaks=c(1:15)) + 
  labs(title="Screeplot: Number of clusters", x="Number of clusters", y="WSS")
```




```{r}
#hc <- sATM[,vars2] %>%
#  hcut(hc_func = "hclust", 
#       k = 4, 
#       stand = TRUE)

#hc %>%
#  fviz_dend( k=4 ,rect = TRUE, cex = 0.5)
```


# Combination

We plot the 

```{r PCA CLUSTER, fig.height=4, fig.width=10}
set.seed(250920198)

km <- sATM[,vars2] %>% 
  scale() %>% 
  kmeans(centers = 4, nstart = 20) 

df <- pca$x %>% as_tibble %>% select(PC1, PC2)
df$cluster <- km$cluster
eigen <- pca$rotation

points <- (km$centers) %*% (eigen) %>% 
  as_tibble %>% 
  mutate(N=c("PC1", "PC2", "PC3", "PC4")) %>% 
  gather(variable, value,-N) %>% 
  spread(key = N, value = value) %>% 
  mutate(variable2=c(2,1,3,4))

df %>% 
  ggplot(aes(PC1,PC2)) + 
  geom_point(aes(color=as.factor(cluster)), alpha=0.3, show.legend = F) + 
  scale_color_tableau(palette = "Classic Cyclic", type = "regular") + 
  scale_fill_tableau(palette = "Classic Cyclic", type = "regular") + 
  geom_point(data=points, aes(PC2,PC1, fill=as.factor(variable2)), inherit.aes = F, size=5, shape=21, color="black") + 
  labs(title="Kmeans clusters displayed in first two PCA components", 
       subtitle="Centroids are created by multiplying the centers by the eigen vector from PCA", 
       fill = "Clusters")
```





```{r}
sATM %>%
  bind_cols(cluster = km$cluster) %>%
  select(vars2, cluster) %>%
  select(-atm_street_number, -atm_zipcode, -weather_city_id, -weather_id, -atm_id) %>% 
  group_by(cluster) %>%
  mutate(n = n()) %>%
  summarise_all(funs(mean)) %>%
  mutate_all(funs(round(.,2))) %>% 
  kable %>% 
  kable_styling("condensed")
```










## Supervised Models
We're fitting 6 different models to the data. One big challenge is that we have alot of observations, 2.5m, and that


```{r}
cv <- trainControl(method = "cv", number = 5)

ml <- fbATM
ml$Euro <- as.factor(ifelse(ml$Euro == "TRUE", "Yes", "No"))

index    <- createDataPartition(ml$Euro, p = 0.03, list = FALSE)
training <- ml[index,] 
test     <- ml[-index,] 
```


### Normal sampeling

```{r MODELS, message=FALSE, warning=FALSE}

a <- Sys.time()
fit_log <- train(Euro ~ .,
                 data      = training,
                 trControl = cv, 
                 method    = "glm", 
                 family    = "binomial",
                 metric    = 'Accuracy')
b <- Sys.time()
fit_tre <- train(Euro ~ .,
                 data      = training, 
                 trControl = cv, 
                 metric    = "Kappa",
                 method    = "rpart", 
                 tuneGrid  = expand.grid(cp = c(0.001, 0.005)))
c <- Sys.time()

fit_bag <- train(Euro ~ ., 
                 data      = training, 
                 method    = "treebag",
                 nbagg     = 50,
                 metric    = "ROC",
                 trControl = trainControl(method = "cv", number = 5, classProbs = T))
d <- Sys.time()

fit_raf <- train(Euro ~ ., 
                 data      = sample_n(training, 500),
                 trControl = cv,
                 tuneGrid  = expand.grid(.mtry = (1:7)),
                 method    = 'rf',
                 metric    = 'Accuracy')
e <- Sys.time()
fit_svm <- train(Euro ~ ., 
                 data      = sample_n(training, 500),
                 trControl = cv,
                 tuneGrid  = expand.grid(C = 10^seq(1, -1, by = -0.02)),
                 method    = 'svmLinear',
                 metric    = 'Accuracy')
f<- Sys.time()
```


```{r TIME}
cat(paste0("Logistic: ", round(difftime(b,a, units = "mins"),2),"\n",
           "Tree:     ", round(difftime(c,b, units = "mins"),2),"\n",
           "Bagged:   ", round(difftime(d,c, units = "mins"),2),"\n",
           "RF:       ", round(difftime(e,d, units = "mins"),2),"\n",
           "SVM:      ", round(difftime(f,e, units = "mins"),2),"\n",
           "Total:    ", round(difftime(f,a, units = "mins"),2),"\n"))

```



```{r CONF}
conf_bag <- table(predict(fit_bag,  test), test$Euro)
#conf_bag

conf_tre <- table(predict(fit_tre,  test), test$Euro)
#conf_tre

conf_log <- table(predict(fit_log,  test), test$Euro)
#conf_log

conf_raf <- table(predict(fit_raf,  test), test$Euro)
#conf_raf

conf_svm <- table(predict(fit_svm,  test), test$Euro)
#conf_svm

random   <- rbinom(n = length(test$Euro), size = 1, prob = mean(training$Euro == "Yes"))
conf_ran <- table(as.factor(if_else(random == 1, "Yes", "No")), test$Euro)
#conf_ran
```



```{r}
kable(cbind(conf_bag, conf_tre, conf_log, conf_raf, conf_svm, conf_ran)) %>% 
  kable_styling("bordered", "condensed") %>%
  column_spec(1, bold = T, color="black") %>%
  add_header_above(c(" "                             = 1, 
                     "Bagged\nTree"                  = 2, 
                     "Classification\nTree"          = 2, 
                     "Logistic\nRegression"          = 2, 
                     "Random\nForrest"               = 2, 
                     "Support Vector\nMachines"      = 2,
                     "Random\nAssignment"            = 2))
```





```{r fig.height=6, fig.width=10}
bag <- rbind(spec(conf_bag), precision(conf_bag), accuracy(conf_bag), recall(conf_bag), npv(conf_bag))
tre <- rbind(spec(conf_tre), precision(conf_tre), accuracy(conf_tre), recall(conf_tre), npv(conf_tre))
raf <- rbind(spec(conf_raf), precision(conf_raf), accuracy(conf_raf), recall(conf_raf), npv(conf_raf))
log <- rbind(spec(conf_log), precision(conf_log), accuracy(conf_log), recall(conf_log), npv(conf_log))
ran <- rbind(spec(conf_ran), precision(conf_ran), accuracy(conf_ran), recall(conf_ran), npv(conf_ran))
svm <- rbind(spec(conf_svm), precision(conf_svm), accuracy(conf_svm), recall(conf_svm), npv(conf_svm))

bag$model <- "Bagged Tree"
tre$model <- "Classification Tree"
raf$model <- "Random Forrest"
log$model <- "Logistic Regression"
ran$model <- "Random Assignment"
svm$model <- "Support Vector Machines"

#df <- rbind(log, lok, ran, net, raf, svm)

df <- rbind(ran, log, tre, bag, svm, raf)

ggplot(df, aes(.metric, .estimate, fill = reorder(model, desc(.estimate)))) + 
  geom_col(position="dodge", width = 0.6) + 
  scale_fill_tableau(palette = "Classic Cyclic", type = "regular") + 
  labs(title="Model performance on predicting Legendary status", 
       subtitle="Crossvalidated 1/5 split", fill="Predictive Model")
```



### Down Sampeling









```{r}
#cv <- trainControl(method = "cv", number = 5, sampling = "down")
#
#ml <- fdata
#ml$Euro <- as.factor(ifelse(ml$Euro == "TRUE", "Yes", "No"))
#
#index    <- createDataPartition(ml$Euro, p = 0.10, list = FALSE)
#training <- ml[index,] 
#test     <- ml[-index,] 
#
#a <- Sys.time()
#fit_log <- train(Euro ~ .,
#                 data      = training,
#                 trControl = cv, 
#                 method    = "glm", 
#                 family    = "binomial",
#                 metric    = 'Accuracy')
#b <- Sys.time()
```

















